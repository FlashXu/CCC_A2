version: '3'

services:
  backend:
    container_name: backend
    build: backend
    ports: 
      - 5000:5000
    volumes:
      - ./backend:/code
    depends_on:
      - redis
    logging:
      options:
        max-size: 10m
    restart: always

  redis:
    container_name: redis
    image: redis:alpine
    restart: always
    
  frontend:
    container_name: frontend
    build: frontend
    ports:
      - 80:80
    restart: always

  stream_harvester:
    container_name: stream_harvester
    build: harvester
    image: python:90024
    command: TwitterStream.py
    volumes:
      - '{{ working_dir }}/harvester:/workspace'
    logging:
      options:
        max-size: 10m

  user_expansion:
    container_name: expansion
    build: harvester
    image: python:90024
    command: api_expand.py
    volumes:
      - '{{ working_dir }}/harvester:/workspace'
    logging:
      options:
        max-size: 10m

  sa_classifier:
    container_name: classifier
    build:
      context: harvester
      dockerfile: Dockerfile_shapely
    image: python:shapely
    command: add_sa.py
    volumes:
      - '{{ working_dir }}/harvester:/workspace'
      - '{{ working_dir }}/aurin/SA2.json:/workspace/SA2.json'
    logging:
      options:
        max-size: 10m
